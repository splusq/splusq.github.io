<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI/ML on Salman Quazi</title><link>https://www.salmanq.com/tags/ai/ml/</link><description>Recent content in AI/ML on Salman Quazi</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>Salman Quazi</managingEditor><lastBuildDate>Mon, 01 Apr 2013 07:39:37 +0000</lastBuildDate><atom:link href="https://www.salmanq.com/tags/ai/ml/index.xml" rel="self" type="application/rss+xml"/><item><title>Introduction to Machine Learning</title><link>https://www.salmanq.com/blog/introduction-to-machine-learning-2/</link><pubDate>Mon, 01 Apr 2013 07:39:37 +0000</pubDate><author>Salman Quazi</author><guid>https://www.salmanq.com/blog/introduction-to-machine-learning-2/</guid><description>&lt;p&gt;In most computer science programs, machine learning is usually a graduate level course. It&amp;rsquo;s a specialization within the field of artificial intelligence, which is often thought of as a theoretical study than practical applications. But yet, machine learning today is used heavily to solve problems. Our team for instance, uses it to build acoustic models for speech recognition. It&amp;rsquo;s no longer a theory, it&amp;rsquo;s applied science. But if you wanted to start in this field, which I suspect is going to play a major role in software in the future, where do you start? I came across this free textbox from professor &lt;a href="http://www.ics.uci.edu/~welling/"&gt;Max Welling&lt;/a&gt; for UCI Computer Science. His textbook &lt;a href="http://www.ics.uci.edu/~welling/teaching/273ASpring10/IntroMLBook.pdf"&gt;&amp;ldquo;A First Encounter with Machine Learning&amp;rdquo;&lt;/a&gt; is available for free. While it&amp;rsquo;s not an entirely bedside reading, it is however written for engineers who are interested in learning about the various machine learning algorithms that are available today.&lt;/p&gt;</description></item><item><title>Alpha Beta Searching</title><link>https://www.salmanq.com/blog/alpha-beta-searching/</link><pubDate>Wed, 26 May 2004 04:58:27 +0000</pubDate><author>Salman Quazi</author><guid>https://www.salmanq.com/blog/alpha-beta-searching/</guid><description>&lt;p&gt;I have a test tonight. I am fairly certain I will get an A; however, there is only one thing that I am unsure about: AlphaBeta searching. So I went online and read couple of books. Here&amp;rsquo;s my understanding (in brief of course): AlphaBeta searching is an optimized searching model based on MinMax searching (or MiniMax search). So to understand AlphaBeta searching we must first understand MinMax searching. MinMax searching can be applied on game trees (if you are not familiar with game trees then please &lt;a href="http://www.google.com/search?hl=en&amp;amp;ie=UTF-8&amp;amp;q=Game+Trees"&gt;go here&lt;/a&gt;). The MinMax comes from the fact that the searching algorithm alternates between searching for a maximum value, and a minimum value. For instance, if it&amp;rsquo;s the computers move then the computer searches for a maximum node (when I refer to maximum I am referring to the move-value which is the heuristic value for that move). On the other hand, when it turn for the opponents move the computer searches for a MIN value and so on. AlphaBeta searching improves on the MinMax algorithm with the following assumption. Lets say you know a node K is better than node K&amp;rsquo; and you can prove that the best possible move can be K then how much better is K than K&amp;rsquo; is absolutely irrelivant because no matter what value K&amp;rsquo; is you will end up choosing K because K is the best move. Therefore if K&amp;rsquo; had a subtree none of that needs to be computed which eventually saves tremendous amount of time.&lt;/p&gt;</description></item></channel></rss>